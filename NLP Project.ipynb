{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndubuisijosephalx/Data-Science-projects/blob/main/Ndubuisi_J_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX0Pnt6GiJVb",
        "outputId": "ec1d1d6d-fbfb-451a-8b5f-5c3336f269cb"
      },
      "id": "qX0Pnt6GiJVb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32faeac4",
      "metadata": {
        "id": "32faeac4"
      },
      "source": [
        "### Assignment # 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dfec9f2",
      "metadata": {
        "id": "7dfec9f2"
      },
      "source": [
        "Q1. How many default stop words are available in each of the 3 spacy packages: 'en_core_web_sm', 'en_core_web_md', 'en_core_web_sm'. Show it with code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41bbc6e6",
      "metadata": {
        "id": "41bbc6e6"
      },
      "source": [
        "Q2. Find if the following words are stop words in Spacy\n",
        "1. hundred\n",
        "2. thousand\n",
        "3. top\n",
        "4. bottom\n",
        "5. niggle\n",
        "\n",
        "Use the below command to load spacy\n",
        "nlp = spacy.load('en_core_web_sm').\n",
        "\n",
        "You have to show the python code and print the output to prove your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3c1fce5",
      "metadata": {
        "id": "d3c1fce5"
      },
      "source": [
        "Q3. Write the python code to remove the stop words from the following sentence:\n",
        "    \n",
        "\"I am not sure how many stop words are in this sentence but we need to remove all the stop words using coding logic\"\n",
        "\n",
        "You should write a coding logic that will take the original sentence, automatically remove all the stopwords\n",
        "and then print the final resulting sentence. DO NOT MANUALLY DELETE EACH STOP WORD AND PRINT THE REMAINING WORDS."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e59a2245",
      "metadata": {
        "id": "e59a2245"
      },
      "source": [
        "Q4. Add the word \"nationality\" as a default stop word. Write the logic to show that you were succesful in including it\n",
        "as a default stopword."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import spacy\n",
        "#import nltk\n",
        "# Download the 'punkt' resource\n",
        "#nltk.download('punkt')!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "id": "VIU9RfW2jI1Z"
      },
      "id": "VIU9RfW2jI1Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Solutions"
      ],
      "metadata": {
        "id": "IarOxnZji3RI"
      },
      "id": "IarOxnZji3RI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##No. 1\n",
        "\n",
        "###The default stop words available in each of the 3 spacy packages: 'en_core_web_sm', 'en_core_web_md', 'en_core_web_sm'can be viewed in the code shown below"
      ],
      "metadata": {
        "id": "x5BVNsNClLHO"
      },
      "id": "x5BVNsNClLHO"
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load each package\n",
        "packages = ['en_core_web_sm', 'en_core_web_md', 'en_core_web_lg']\n",
        "\n",
        "for package in packages:\n",
        "    nlp = spacy.load(package)\n",
        "    stop_words_count = len(nlp.Defaults.stop_words)\n",
        "    print(f\"Package: {package}\\tNumber of Default Stop Words: {stop_words_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USwQfjvYi1nQ",
        "outputId": "b057230a-d2ab-49bd-ad75-a9a9a8ea0f4b"
      },
      "id": "USwQfjvYi1nQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package: en_core_web_sm\tNumber of Default Stop Words: 326\n",
            "Package: en_core_web_md\tNumber of Default Stop Words: 326\n",
            "Package: en_core_web_lg\tNumber of Default Stop Words: 326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##No. 2\n",
        "\n",
        "### To ascertain if the following words are stop words in Spacy\n",
        "hundred, thousand, top, bottom, niggle, we will do the following shown in the code below"
      ],
      "metadata": {
        "id": "zKV2HJrHlLdZ"
      },
      "id": "zKV2HJrHlLdZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# load the package\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Define the list of words to check\n",
        "words = ['hundred', 'thousand', 'top', 'bottom', 'niggle']\n",
        "\n",
        "# iterate over each word in the list\n",
        "for word in words:\n",
        "    # Check if word is a stop word or not with \"is_stop\"\n",
        "    is_stop_word = nlp.vocab[word].is_stop\n",
        "    # Display if each word Kyin the list is a stop word or not\n",
        "    print(f\"{word}: {is_stop_word}\")"
      ],
      "metadata": {
        "id": "EuNrZai6lJVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e031af-4387-495b-f188-95342225a6cc"
      },
      "id": "EuNrZai6lJVZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hundred: True\n",
            "thousand: False\n",
            "top: True\n",
            "bottom: True\n",
            "niggle: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display the default stop words and the total number in spacy"
      ],
      "metadata": {
        "id": "YF-0kcSLR9NX"
      },
      "id": "YF-0kcSLR9NX"
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = nlp.Defaults.stop_words\n",
        "print(stop_words)\n",
        "print(len(stop_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVHmBBRwKPCG",
        "outputId": "dbe80a51-d216-4570-93f6-6d1c300faa3c"
      },
      "id": "GVHmBBRwKPCG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'noone', 'i', 'beforehand', 'seemed', \"'m\", 'whereafter', 'ca', 'his', 'part', 'take', 'not', 'yet', 'nobody', 'made', 'even', 'meanwhile', 'nothing', 'most', 'its', 'else', 'eight', 'whole', 'beyond', \"'re\", 'whoever', 'throughout', 'own', 'further', 'over', 'alone', 'get', 'nowhere', 'there', 'several', 'until', 'wherever', 'therein', 'across', 'eleven', 'thereby', 'such', 'seem', 'of', 'becoming', 'third', 'namely', 'twenty', 'up', 'other', '’ve', 'than', 'via', 'whether', 'four', 'sometime', 'using', 'still', 'yours', 'within', 'never', 'rather', 'front', 'nevertheless', '‘d', 'can', 'yourselves', 'whereupon', 'hers', 'herein', 'next', 'amount', 'five', \"'ve\", 'thereafter', 'while', 'should', 'who', 'n‘t', 'being', 're', 'below', 'their', \"'s\", 'when', 'first', 'call', 'ten', 'our', 'both', 'were', 'ever', 'your', 'somehow', 'must', '‘re', 'empty', 'we', 'became', 'none', 'at', 'whatever', 'every', 'has', 'my', 'former', 'latterly', 'about', 'whence', 'very', 'also', 'her', 'are', 'afterwards', 'onto', 'become', '’s', 'these', 'full', 'unless', '‘ll', 'if', 'around', 'nor', 'forty', 'mine', 'well', 'back', 'themselves', 'anyhow', 'hence', 'here', 'by', 'toward', 'anyway', 'elsewhere', 'which', 'why', 'hereafter', 'been', '‘m', 'serious', 'had', 'thence', 'mostly', 'might', 'top', 'used', 'those', 'often', 'neither', 'therefore', 'yourself', 'hundred', 'through', 'since', 'he', 'some', 'how', 'various', 'hereby', 'out', '‘s', 'seems', 'am', 'per', 'anyone', 'everything', 'sixty', 'him', 'move', 'fifteen', 'once', 'again', 'latter', 'formerly', 'along', 'in', 'be', 'an', 'two', 'six', 'off', '’re', 'did', 'whither', 'she', 'go', 'then', 'seeming', 'whereby', 'except', 'just', 'any', 'due', 'all', 'really', 'together', 'will', 'itself', 'done', 'more', 'under', 'where', 'what', 'behind', 'into', 'each', 'make', 'indeed', 'anything', 'anywhere', 'is', 'three', 'could', 'during', \"'ll\", 'everywhere', 'last', 'myself', 'that', 'wherein', 'give', 'himself', 'does', 'against', 'among', 'otherwise', 'twelve', 'sometimes', 'towards', 'another', '’m', 'thereupon', 'from', 'only', 'much', 'although', 'without', 'and', 'whom', 'would', 'becomes', 'amongst', 'somewhere', 'or', 'quite', 'thus', 'whenever', 'cannot', 'was', 'hereupon', 'moreover', 'this', 'thru', 'for', 'keep', 'you', 'whose', 'side', 'on', 'whereas', 'after', 'besides', 'something', 'it', 'me', 'before', 'always', 'ours', 'show', 'one', 'may', 'herself', 'ourselves', 'fifty', 'no', 'beside', 'to', 'same', 'them', 'however', 'with', 'everyone', 'less', 'already', 'others', 'see', 'enough', 'many', 'doing', 'because', 'almost', 'they', 'too', 'least', 'as', 'upon', 'regarding', 'n’t', 'either', 'so', 'few', 'a', 'the', 'down', '’ll', '‘ve', 'have', 'bottom', 'nine', 'someone', 'put', 'do', 'between', 'name', 'please', 'but', \"'d\", 'though', 'say', 'now', \"n't\", 'perhaps', '’d', 'us', 'above'}\n",
            "326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using for loop to check if each word in the list of words is a stop word or not"
      ],
      "metadata": {
        "id": "3rwWiKvbQCZk"
      },
      "id": "3rwWiKvbQCZk"
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['hundred', 'thousand', 'top', 'bottom', 'niggle']\n",
        "for word in stop_words:\n",
        "    if word in words:\n",
        "        print(\"Stop word:\",word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZSLZp8TLZJM",
        "outputId": "8ae85022-62fc-4d1a-e45a-db8fa8694b9e"
      },
      "id": "iZSLZp8TLZJM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop word: top\n",
            "Stop word: hundred\n",
            "Stop word: bottom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using list expression"
      ],
      "metadata": {
        "id": "HMPm5TZ8QIsG"
      },
      "id": "HMPm5TZ8QIsG"
    },
    {
      "cell_type": "code",
      "source": [
        "StopWords = [word for word in stop_words if word in words]\n",
        "print(f\"These are the list of the stop words: {StopWords}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88RHu6S3PspB",
        "outputId": "531185ea-7776-4095-89a1-f80447114602"
      },
      "id": "88RHu6S3PspB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These are the list of the stop words: ['top', 'hundred', 'bottom']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##No. 3\n",
        "\n",
        "### The python code below remove the stop words from the sentence provided in question 3 using spacy library"
      ],
      "metadata": {
        "id": "Wnp4792rr3w9"
      },
      "id": "Wnp4792rr3w9"
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(sentence):\n",
        "    # Load the English language model in spaCy\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "    # Process the sentence\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    # Remove the stop words from the document\n",
        "    filtered_words = [token.text for token in doc if not token.is_stop]\n",
        "\n",
        "    # Join the filtered words back into a sentence\n",
        "    filtered_sentence = ' '.join(filtered_words)\n",
        "\n",
        "    return filtered_sentence\n",
        "\n",
        "# Test the function\n",
        "sentence = \"I am not sure how many stop words are in this sentence but we need to remove all the stop words using coding logic\"\n",
        "result = remove_stop_words(sentence)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK8zbyGhAtZu",
        "outputId": "ed0868a7-7d4b-4769-cbc2-6e5fd761fa9a"
      },
      "id": "AK8zbyGhAtZu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sure stop words sentence need remove stop words coding logic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another Logic Method to Remove Stop Words"
      ],
      "metadata": {
        "id": "xOnxyOL0dyEM"
      },
      "id": "xOnxyOL0dyEM"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Default stop words\n",
        "default_stop_words = nlp.Defaults.stop_words\n",
        "# Sentence to remove stop words\n",
        "sentence = \"I am not sure how many stop words are in this sentence but we need to remove all the stop words using coding logic\"\n",
        "# Tokenize the sentence\n",
        "tokenize = sentence.split()\n",
        "# iterate over each sentence\n",
        "for word in tokenize:\n",
        "    # Remove the stop words in the sentence\n",
        "    if word not in default_stop_words:\n",
        "        # Display the result\n",
        "        print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pzNetvYXEI7",
        "outputId": "9a06ab99-6467-4d82-b6f7-0cd132a2cf23"
      },
      "id": "6pzNetvYXEI7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "sure\n",
            "stop\n",
            "words\n",
            "sentence\n",
            "need\n",
            "remove\n",
            "stop\n",
            "words\n",
            "coding\n",
            "logic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(sentence)"
      ],
      "metadata": {
        "id": "YJMCn9wSaZ7z"
      },
      "id": "YJMCn9wSaZ7z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCBXC8TdbdHg",
        "outputId": "4709a1ae-8608-4fe1-a41d-2d93f2743e86"
      },
      "id": "DCBXC8TdbdHg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "I am not sure how many stop words are in this sentence but we need to remove all the stop words using coding logic"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using nltk"
      ],
      "metadata": {
        "id": "PK0JAwcaCYWR"
      },
      "id": "PK0JAwcaCYWR"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the stopwords corpus if it's not already available\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def remove_stopwords(sentence):\n",
        "    # Retrieve the set of English stop words from the stopwords corpus\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Tokenize the sentence into individual words\n",
        "    word_tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "    # Filter out the stop words from the word tokens using list comprehension\n",
        "    filtered_sentence = [word for word in word_tokens if word.casefold() not in stop_words]\n",
        "\n",
        "    # Join the filtered words back into a sentence\n",
        "    return ' '.join(filtered_sentence)\n",
        "\n",
        "# The original sentence to remove stop words from\n",
        "original_sentence = \"I am not sure how many stop words are in this sentence but we need to remove all the stop words using coding logic\"\n",
        "\n",
        "# Remove stop words from the original sentence\n",
        "final_sentence = remove_stopwords(original_sentence)\n",
        "\n",
        "# Print the final filtered sentence\n",
        "print(final_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lim2NyWNr89J",
        "outputId": "21894f9b-c3cf-479e-9993-3ade332936ab"
      },
      "id": "Lim2NyWNr89J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sure many stop words sentence need remove stop words using coding logic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##No. 4\n",
        "\n",
        "### To Add the word \"nationality\" as a default stop word, we will use the code below"
      ],
      "metadata": {
        "id": "6mLpw7WGxIDE"
      },
      "id": "6mLpw7WGxIDE"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Add \"nationality\" to the set of default stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.add('nationality')\n",
        "\n",
        "# Check if \"nationality\" is in the default stop words\n",
        "if 'nationality' in stop_words:\n",
        "    print(\"Successfully included 'nationality' as a default stop word.\")\n",
        "else:\n",
        "    print(\"Failed to include 'nationality' as a default stop word.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADyvavtV5oUX",
        "outputId": "b5d38737-51e5-4b72-a485-130caa70d8f0"
      },
      "id": "ADyvavtV5oUX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully included 'nationality' as a default stop word.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check if the added stop word exist as a default stopword\n",
        "\"nationality\" in stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fckspoio5uOi",
        "outputId": "fefa0929-04a1-4296-e70f-704aa258328e"
      },
      "id": "fckspoio5uOi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the default stop words and check if \"nationality\" is present\n",
        "print(f\"Stop words{stop_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_R-SoYe6T3x",
        "outputId": "2410b274-41f4-4071-ae31-7cb7297ec814"
      },
      "id": "V_R-SoYe6T3x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop words{'shan', \"shouldn't\", 'i', 'in', 'y', 'ma', 'this', 'we', 'll', 'for', 'be', 'his', \"doesn't\", 'you', 'an', 'at', 'needn', \"haven't\", 'off', 'not', 'wasn', 'on', 'weren', 'has', 'my', \"you'll\", 'after', 'most', \"she's\", 'mustn', 'did', 'she', 'about', 'then', 'its', 'very', 'it', \"wasn't\", 'just', 'me', 'her', 'before', 'are', 'm', 'any', 'own', 'having', 'all', 'these', 'ours', 'further', 'aren', 'd', 'over', 'herself', 'itself', 'will', 'haven', 'more', 'under', 'ourselves', 'where', 'what', 'no', 'to', 'into', 'if', 'them', 'each', 'same', 'there', 'until', 'nor', 'theirs', 'shouldn', 'such', 'with', 'is', \"aren't\", 'themselves', 'during', \"weren't\", 'of', 'ain', \"isn't\", \"you'd\", 'up', 'here', 'won', \"wouldn't\", 'other', 'doing', 'by', 'because', 'than', \"mightn't\", 'they', 'couldn', \"mustn't\", 'too', 'myself', 'that', 'why', 'which', 'himself', 'been', 'didn', 'does', 'as', 'had', 'o', 'yours', 'hasn', 'against', 'don', \"don't\", 'so', 'few', \"couldn't\", 'can', 'wouldn', 'yourselves', 'a', 'the', 'down', 'hadn', 'those', 'hers', 'have', 'yourself', \"didn't\", 'through', 's', \"hadn't\", 'from', 'only', \"should've\", 'he', 'some', 'do', 'how', 'and', 'whom', \"needn't\", 'between', 'while', 'mightn', 'out', 'who', 'should', 'being', 'but', 'am', 're', 't', 'below', 'their', 'isn', 'or', 'when', \"you're\", 'now', \"you've\", 've', 'doesn', 'nationality', 'our', \"won't\", \"shan't\", 'him', 'both', \"that'll\", 'were', 'above', \"it's\", 'once', 'again', 'your', \"hasn't\", 'was'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for word in stop_words: # Iterate over the default stop words\n",
        "    if word == \"nationality\":# check if \"nationality\" is in the  default stopwords\n",
        "        print(word) # if yes, display the word \"nationality\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H1jv3Pc6p1x",
        "outputId": "9e3fc29f-61c5-4d35-d3bd-b6aa649d2939"
      },
      "id": "1H1jv3Pc6p1x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nationality\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
