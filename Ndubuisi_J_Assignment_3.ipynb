{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndubuisijosephalx/Data-Science-projects/blob/main/Ndubuisi_J_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef3e84ec",
      "metadata": {
        "id": "ef3e84ec"
      },
      "source": [
        "### Assignment # 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNLvRnmdBMTi",
        "outputId": "804775fc-f742-4ed6-dd9c-ad38b01564c7"
      },
      "id": "RNLvRnmdBMTi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/PyYAML-6.0.dist-info/my libaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIdH8BDOB2rv",
        "outputId": "6ff12c7a-508c-4294-8379-2878e60ffd69"
      },
      "id": "ZIdH8BDOB2rv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/PyYAML-6.0.dist-info/my libaries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRdirPpMB9-R",
        "outputId": "b7889b75-6002-4ccf-ea4e-f8d7713c76e3"
      },
      "id": "NRdirPpMB9-R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/PyYAML-6.0.dist-info/my libaries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17bdd9ca",
      "metadata": {
        "id": "17bdd9ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "934508a0-d212-480b-df79-739aa988f19c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-4615cbc1d2f4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    In the word_vectors_1 notebook it is shown how to use spacy embedding vectors to find similarity between the words or tokens\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "In the word_vectors_1 notebook it is shown how to use spacy embedding vectors to find similarity between the words or tokens\n",
        "Now, use the embedding vectors to find similarity between 2 full sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b4eec1",
      "metadata": {
        "id": "c0b4eec1"
      },
      "source": [
        "### Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "534ab0ec",
      "metadata": {
        "id": "534ab0ec"
      },
      "source": [
        "Q1\n",
        "Find the similarity score between the following sentences:\n",
        "\n",
        "text1 = \"i like salty fries and hamburgers\"\n",
        "text2 = \"fast food tastes very good\"\n",
        "\n",
        "Note: you need to find the similarity score between the 2 full sentences, and NOT the similarity scores between\n",
        "the individual words as was shown in the word_vectors_1 notebook. Provide the python code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fa8f7a8",
      "metadata": {
        "id": "3fa8f7a8"
      },
      "source": [
        "### Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e47b72",
      "metadata": {
        "id": "99e47b72"
      },
      "source": [
        "Q2\n",
        "Is the similarity score giving a reasonably good indication of the similarity between the 2 sentences?\n",
        "\n",
        "If your answer is YES, you don't need to give any explanation.\n",
        "\n",
        "If your answer is NO, give a probable reason why spacy is getting confused. Why is Spacy getting it wrong?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4481c9e6",
      "metadata": {
        "id": "4481c9e6"
      },
      "source": [
        "### Q3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cace294c",
      "metadata": {
        "id": "cace294c"
      },
      "source": [
        "Q3\n",
        "Find the similarity score between the following sentences:\n",
        "\n",
        "text1 = \"river bank\"\n",
        "text2 = \"bank account\"\n",
        "\n",
        "Note: you need to find the similarity score between the 2 full sentences, and NOT the similarity scores between\n",
        "the individual words as was shown in the word_vectors_1 notebook. Provide the python code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02fdf4d6",
      "metadata": {
        "id": "02fdf4d6"
      },
      "source": [
        "### Q4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe1ffc60",
      "metadata": {
        "id": "fe1ffc60"
      },
      "source": [
        "Q4\n",
        "Is the similarity score giving a reasonably good indication of the similarity between the 2 sentences?\n",
        "\n",
        "If your answer is YES, you don't need to give any explanation.\n",
        "\n",
        "If your answer is NO, give a probable reason why spacy is getting confused. Why is Spacy getting it wrong?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fda0d45",
      "metadata": {
        "id": "7fda0d45"
      },
      "source": [
        "# No. 1 Solution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "h-AIcwDjGK04"
      },
      "id": "h-AIcwDjGK04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "HetFumtUZlUL"
      },
      "id": "HetFumtUZlUL",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WglINkRYEcoN",
        "outputId": "54b15ffb-692c-447e-e096-dd5766375a62"
      },
      "id": "WglINkRYEcoN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-16 09:49:51.024325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.11)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "nlp2 = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "7QOLpMlWGhp-"
      },
      "id": "7QOLpMlWGhp-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let check if the word 'hamburgers' has a vector and if it exist in our vocabulary. Also we also check for the eucludian for both text1 and text2"
      ],
      "metadata": {
        "id": "yG5PQ4-DDLrk"
      },
      "id": "yG5PQ4-DDLrk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setences in text1 and text2"
      ],
      "metadata": {
        "id": "Q8QR_qwEMzMq"
      },
      "id": "Q8QR_qwEMzMq"
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = nlp(\"i like salty fries and hamburgers\")\n",
        "text2 = nlp(\"fast food tastes very good\")"
      ],
      "metadata": {
        "id": "jUcrTuP3Ek71"
      },
      "id": "jUcrTuP3Ek71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token1,token2 in zip(text1,text2):\n",
        "    print(token1.text,token2.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAO9aDS5IRaS",
        "outputId": "7ba687df-f76c-4e4c-b4eb-2c854da52740"
      },
      "id": "yAO9aDS5IRaS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i fast\n",
            "like food\n",
            "salty tastes\n",
            "fries very\n",
            "and good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check if any of the tokens in text1 and text2 exist in the volcabulary. We will also check for the euclidian norm, and if the tokens has a vector"
      ],
      "metadata": {
        "id": "uKpKFdEkNAOg"
      },
      "id": "uKpKFdEkNAOg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text1  check"
      ],
      "metadata": {
        "id": "TDh6-LKNN50e"
      },
      "id": "TDh6-LKNN50e"
    },
    {
      "cell_type": "code",
      "source": [
        "for token in text1:\n",
        "    print(token.text,token.has_vector,token.vector_norm,token.is_oov)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76bzWn5fLjMF",
        "outputId": "a3b678fa-b9f8-4497-fe89-5a457dba894a"
      },
      "id": "76bzWn5fLjMF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i True 117.51532 False\n",
            "like True 50.609623 False\n",
            "salty True 36.629864 False\n",
            "fries True 49.507717 False\n",
            "and True 60.75837 False\n",
            "hamburgers True 34.503483 False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text2 Check"
      ],
      "metadata": {
        "id": "FKpv-zBJN934"
      },
      "id": "FKpv-zBJN934"
    },
    {
      "cell_type": "code",
      "source": [
        "for tokens in text2:\n",
        "    print(tokens.text,tokens.has_vector,tokens.vector_norm,tokens.is_oov)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnqA3VwiDKwJ",
        "outputId": "a7b88137-e549-4786-b3b7-60dfa0250cec"
      },
      "id": "mnqA3VwiDKwJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fast True 58.29239 False\n",
            "food True 75.153 False\n",
            "tastes True 41.575363 False\n",
            "very True 61.511013 False\n",
            "good True 54.353004 False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the features we just checked in text1 and text2 exist in the pre_trained word embedding model(en_core_web_md). So the medium size word embedding english pre_trained model is enough to address our specific task.\n",
        "\n",
        "Now that we have known this, let proceed with checking for the two sentences similarity. To explicitly explain the similarity between the two sentences, let us have a check on how each token or word  is related to each other in the sentence."
      ],
      "metadata": {
        "id": "-ZU2zefeOlEX"
      },
      "id": "-ZU2zefeOlEX"
    },
    {
      "cell_type": "code",
      "source": [
        "for token1 in text1:\n",
        "    for token2 in text2:\n",
        "        print(token1.text,token2.text,token1.similarity(token2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmEfEm3EQ4PV",
        "outputId": "0ec87935-ae75-40da-ce06-20c086a063d3"
      },
      "id": "fmEfEm3EQ4PV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i fast 0.1280231922864914\n",
            "i food 0.022347047924995422\n",
            "i tastes 0.14268723130226135\n",
            "i very 0.12663251161575317\n",
            "i good 0.20122960209846497\n",
            "like fast 0.24924501776695251\n",
            "like food 0.25689175724983215\n",
            "like tastes 0.3718910813331604\n",
            "like very 0.36990147829055786\n",
            "like good 0.5285202860832214\n",
            "salty fast 0.23733454942703247\n",
            "salty food 0.40850162506103516\n",
            "salty tastes 0.5534480810165405\n",
            "salty very 0.22962722182273865\n",
            "salty good 0.2958960235118866\n",
            "fries fast 0.18381565809249878\n",
            "fries food 0.4907633066177368\n",
            "fries tastes 0.45439693331718445\n",
            "fries very 0.3020797669887543\n",
            "fries good 0.1925533562898636\n",
            "and fast 0.15189145505428314\n",
            "and food 0.326991468667984\n",
            "and tastes 0.05855073034763336\n",
            "and very 0.3279082179069519\n",
            "and good 0.1629762351512909\n",
            "hamburgers fast 0.2480451762676239\n",
            "hamburgers food 0.46927979588508606\n",
            "hamburgers tastes 0.47389858961105347\n",
            "hamburgers very 0.18954713642597198\n",
            "hamburgers good 0.20561638474464417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see it happens that the word like and good have 52% similarity ans so on"
      ],
      "metadata": {
        "id": "ANnVXNsBU3gm"
      },
      "id": "ANnVXNsBU3gm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now Let Compare the two sentences for similarity"
      ],
      "metadata": {
        "id": "uR_eYzeKVMqd"
      },
      "id": "uR_eYzeKVMqd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medium Pre_trained Model"
      ],
      "metadata": {
        "id": "Rj2z9ZbuuX7y"
      },
      "id": "Rj2z9ZbuuX7y"
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "Bni6xmVfkK1p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bni6xmVfkK1p",
        "outputId": "d1621c43-4a8d-41bc-db01-8de6fe4d6e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Score: 0.6227705519265844\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Define the sentences\n",
        "text1 = \"i like salty fries and hamburgers\"\n",
        "text2 = \"fast food tastes very good\"\n",
        "\n",
        "# Process the sentences with spaCy\n",
        "doc1 = nlp(text1)\n",
        "doc2 = nlp(text2)\n",
        "\n",
        "# Calculate the similarity score\n",
        "similarity_score = doc1.similarity(doc2)\n",
        "\n",
        "# Print the similarity score\n",
        "print(\"Similarity Score:\", similarity_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Large Pre_trained Model"
      ],
      "metadata": {
        "id": "FvYKRyk9ugaq"
      },
      "id": "FvYKRyk9ugaq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the spaCy English model\n",
        "nlp2 = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Define the sentences\n",
        "text1 = \"i like salty fries and hamburgers\"\n",
        "text2 = \"fast food tastes very good\"\n",
        "\n",
        "# Process the sentences with spaCy\n",
        "doc_1 = nlp2(text1)\n",
        "doc_2 = nlp2(text2)\n",
        "\n",
        "# Calculate the similarity score\n",
        "similarity_score = doc_1.similarity(doc_2)\n",
        "\n",
        "# Print the similarity score\n",
        "print(\"Similarity Score:\", similarity_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DD5cLgCZZTw",
        "outputId": "bb0f76ec-aaba-4fde-8af4-4ad556217707"
      },
      "id": "1DD5cLgCZZTw",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Score: 0.6128936316913924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above output, there is approximately 62% similarity between the two sentences for the medium pretrained model and approximately 61% for the large pretrained model, but the question is: is the similarity score reasonable enough to justify their similarity, let us find out in solution 2 below"
      ],
      "metadata": {
        "id": "YrXMTSldVhQg"
      },
      "id": "YrXMTSldVhQg"
    },
    {
      "cell_type": "markdown",
      "id": "0b8e2cd1",
      "metadata": {
        "id": "0b8e2cd1"
      },
      "source": [
        "# Solution 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fefd2ca7",
      "metadata": {
        "id": "fefd2ca7"
      },
      "source": [
        "My answer is No, 62% or 61% claim is good not enough.\n",
        "\n",
        "One probable reason why spaCy might be getting confused and providing a misleading similarity score is that the pretrained word vectors used by spaCy, such as the en_core_web_md model, may not adequately capture the semantics and nuances of the given sentences. The pretrained vectors are trained on a large corpus of text, but they might not have specific information about the context or domain of the sentences being compared. Although in our case all the features we are looking for is available in en_core_web_md pretrained model, such as the word embedding vectors, text1 and text2 sentences vocabulary, euclidian norm and so on. For these reasons one may say there is no reason for spacy to be confuse. Let see how true this assertion is.\n",
        "\n",
        "In this case, the sentences \"i like salty fries and hamburgers\" and \"fast food tastes very good\" have some overlapping terms related to food, but they convey different meanings. The first sentence expresses a personal preference for specific types of food, while the second sentence makes a general statement about the taste of fast food. SpaCy's similarity score is based on word vectors and may not be able to accurately capture the overall meaning and intent of the sentences.\n",
        "## How spacy does this:\n",
        "spacy focuses on the patterns of word co-occurrences and the context in which words appear together,then assign a vector represntation to each word in the corpus or sentence. The closer words, are assigned a vector similar to each other. 1 shows a very high similiarity and 0 represent no similarity between the two words.\n",
        "\n",
        "In this case,\n",
        "The similarity method calculates the similarity score based on the vector representations of the words in the sentences. It compares the vectors for each word in the sentences and aggregates the results to produce an overall similarity score.\n",
        "The resulting similarity_score is a float value between 0 and 1, where 1 indicates high similarity and 0 indicates no similarity.\n",
        "\n",
        "To get more accurate results, it is often beneficial to train custom models on domain-specific data or use specialized techniques tailored to the specific task or domain of the sentences being compared."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1d73c0a",
      "metadata": {
        "id": "c1d73c0a"
      },
      "source": [
        "# No. 3 Solution - Medium Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "CygIjUd9VGO1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CygIjUd9VGO1",
        "outputId": "1d0d334c-0de5-46ae-a7b8-c241a4720664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Score: 0.7595661548019256\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Define the sentences\n",
        "text_1 = \"river bank\"\n",
        "text_2 = \"bank account\"\n",
        "\n",
        "# Process the sentences with spaCy\n",
        "doc1 = nlp(text_1)\n",
        "doc2 = nlp(text_2)\n",
        "\n",
        "# Calculate the similarity score\n",
        "similarity_score = doc1.similarity(doc2)\n",
        "\n",
        "# Print the similarity score\n",
        "print(\"Similarity Score:\", similarity_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Large Pre_trained Model"
      ],
      "metadata": {
        "id": "mNUS9v2Eu57K"
      },
      "id": "mNUS9v2Eu57K"
    },
    {
      "cell_type": "code",
      "source": [
        "nlp3 = spacy.load(\"en_core_web_lg\")\n",
        "token_3 = nlp3(text_1)\n",
        "token_4 = nlp3(text_2)\n",
        "print('Similarity score:',token_3.similarity(token_4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBsTf3ZFu43z",
        "outputId": "554bdf47-9474-4142-b407-1ef60b345408"
      },
      "id": "JBsTf3ZFu43z",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: 0.7595661548019256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbe97568",
      "metadata": {
        "id": "dbe97568"
      },
      "source": [
        "# No. 4 Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "900ffac0",
      "metadata": {
        "id": "900ffac0"
      },
      "source": [
        "In this context, the similarity score of approximately 76% is moderately reasonable considering the two sentences.\n",
        "\n",
        "In this case, a score of 0.76 suggests that the two sentences share some similarities in terms of their word usage, context, or meaning. Although the sentences are not identical, they may contain overlapping concepts or associations that contribute to the relatively high similarity score. The discrepancy arises because spaCy's similarity score is based on the word vectors of individual words and their similarity, rather than considering the overall meaning or context of the entire sentence.\n",
        "\n",
        "In this case, \"river bank\" and \"bank account\" have the word \"bank\" in common, but they have different meanings. \"River bank\" refers to the edge of a river, while \"bank account\" refers to a financial account held by a bank. The word \"bank\" has different contextual associations in each sentence, which spaCy's word vectors may not fully capture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60aad846",
      "metadata": {
        "id": "60aad846"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}